{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b3c14f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-12T10:09:03.494581Z",
     "iopub.status.busy": "2024-01-12T10:09:03.494208Z",
     "iopub.status.idle": "2024-01-12T10:09:04.338616Z",
     "shell.execute_reply": "2024-01-12T10:09:04.337455Z"
    },
    "papermill": {
     "duration": 0.870281,
     "end_time": "2024-01-12T10:09:04.341050",
     "exception": false,
     "start_time": "2024-01-12T10:09:03.470769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/suvidha-project/x_test.pkl\n",
      "/kaggle/input/suvidha-project/y_train.pkl\n",
      "/kaggle/input/suvidha-project/x_tokenizer.pkl\n",
      "/kaggle/input/suvidha-project/__results__.html\n",
      "/kaggle/input/suvidha-project/x_val.pkl\n",
      "/kaggle/input/suvidha-project/__resultx__.html\n",
      "/kaggle/input/suvidha-project/x_train.pkl\n",
      "/kaggle/input/suvidha-project/test_data.pkl\n",
      "/kaggle/input/suvidha-project/__notebook__.ipynb\n",
      "/kaggle/input/suvidha-project/__output__.json\n",
      "/kaggle/input/suvidha-project/y_test.pkl\n",
      "/kaggle/input/suvidha-project/y_val.pkl\n",
      "/kaggle/input/suvidha-project/train_data.pkl\n",
      "/kaggle/input/suvidha-project/y_tokenizer.pkl\n",
      "/kaggle/input/suvidha-project/val_data.pkl\n",
      "/kaggle/input/suvidha-project/custom.css\n",
      "/kaggle/input/suvidha-project/final_gru_model/fingerprint.pb\n",
      "/kaggle/input/suvidha-project/final_gru_model/saved_model.pb\n",
      "/kaggle/input/suvidha-project/final_gru_model/keras_metadata.pb\n",
      "/kaggle/input/suvidha-project/final_gru_model/variables/variables.index\n",
      "/kaggle/input/suvidha-project/final_gru_model/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/ckpt_1.index\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/ckpt_2.index\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/ckpt_4.data-00000-of-00001\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/ckpt_2.data-00000-of-00001\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/ckpt_4.index\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/ckpt_5.data-00000-of-00001\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/ckpt_3.data-00000-of-00001\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/ckpt_1.data-00000-of-00001\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/ckpt_3.index\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/ckpt_5.index\n",
      "/kaggle/input/suvidha-project/checkpoints_gru/checkpoint\n",
      "/kaggle/input/suvidha-project/cnn_dailymail/cp.ckpt.index\n",
      "/kaggle/input/suvidha-project/cnn_dailymail/original_summaries.pkl\n",
      "/kaggle/input/suvidha-project/cnn_dailymail/decoded_sentences.pkl\n",
      "/kaggle/input/suvidha-project/cnn_dailymail/seq2seq_model.h5\n",
      "/kaggle/input/suvidha-project/cnn_dailymail/cp.ckpt.data-00000-of-00001\n",
      "/kaggle/input/suvidha-project/cnn_dailymail/checkpoint\n",
      "/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\n",
      "/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\n",
      "/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\n",
      "/kaggle/input/decoded/original_summaries.pkl\n",
      "/kaggle/input/decoded/decoded_sentences.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17680f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:09:04.385336Z",
     "iopub.status.busy": "2024-01-12T10:09:04.384879Z",
     "iopub.status.idle": "2024-01-12T10:09:18.836894Z",
     "shell.execute_reply": "2024-01-12T10:09:18.835995Z"
    },
    "papermill": {
     "duration": 14.477388,
     "end_time": "2024-01-12T10:09:18.839441",
     "exception": false,
     "start_time": "2024-01-12T10:09:04.362053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import nltk\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, Concatenate, GRU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7deed296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:09:18.882639Z",
     "iopub.status.busy": "2024-01-12T10:09:18.881988Z",
     "iopub.status.idle": "2024-01-12T10:09:32.374263Z",
     "shell.execute_reply": "2024-01-12T10:09:32.373179Z"
    },
    "papermill": {
     "duration": 13.515965,
     "end_time": "2024-01-12T10:09:32.376271",
     "exception": false,
     "start_time": "2024-01-12T10:09:18.860306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\r\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\r\n",
      "Installing collected packages: rouge\r\n",
      "Successfully installed rouge-1.0.1\r\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install rouge\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b930b7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:09:32.421102Z",
     "iopub.status.busy": "2024-01-12T10:09:32.420702Z",
     "iopub.status.idle": "2024-01-12T10:09:32.425894Z",
     "shell.execute_reply": "2024-01-12T10:09:32.425014Z"
    },
    "papermill": {
     "duration": 0.030121,
     "end_time": "2024-01-12T10:09:32.427844",
     "exception": false,
     "start_time": "2024-01-12T10:09:32.397723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load datasets\n",
    "# train_data = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv')\n",
    "# validate_data = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv')\n",
    "# test_data = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv')\n",
    "\n",
    "# # Data cleaning function\n",
    "# def clean_text(text):\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'\\s+', ' ', text)\n",
    "#     text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "#     return text\n",
    "\n",
    "# # Preprocess the data\n",
    "# train_data['cleaned_article'] = train_data['article'].apply(clean_text)\n",
    "# train_data['cleaned_highlights'] = train_data['highlights'].apply(clean_text)\n",
    "\n",
    "# validate_data['cleaned_article'] = validate_data['article'].apply(clean_text)\n",
    "# validate_data['cleaned_highlights'] = validate_data['highlights'].apply(clean_text)\n",
    "\n",
    "# test_data['cleaned_article'] = test_data['article'].apply(clean_text)\n",
    "# test_data['cleaned_highlights'] = test_data['highlights'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c361900b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:09:32.471550Z",
     "iopub.status.busy": "2024-01-12T10:09:32.471202Z",
     "iopub.status.idle": "2024-01-12T10:09:32.475310Z",
     "shell.execute_reply": "2024-01-12T10:09:32.474445Z"
    },
    "papermill": {
     "duration": 0.027887,
     "end_time": "2024-01-12T10:09:32.477111",
     "exception": false,
     "start_time": "2024-01-12T10:09:32.449224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # saving data pickle\n",
    "# train_data.to_pickle('/kaggle/input/suvidha-project/train_data.pkl')\n",
    "# validate_data.to_pickle('/kaggle/input/suvidha-project/val_data.pkl')\n",
    "# test_data.to_pickle('/kaggle/input/suvidha-project/test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f0bdda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:09:32.520218Z",
     "iopub.status.busy": "2024-01-12T10:09:32.519867Z",
     "iopub.status.idle": "2024-01-12T10:09:55.508409Z",
     "shell.execute_reply": "2024-01-12T10:09:55.507548Z"
    },
    "papermill": {
     "duration": 23.013089,
     "end_time": "2024-01-12T10:09:55.510794",
     "exception": false,
     "start_time": "2024-01-12T10:09:32.497705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# And to load:\n",
    "train_data = pd.read_pickle('/kaggle/input/suvidha-project/train_data.pkl')\n",
    "validate_data = pd.read_pickle('/kaggle/input/suvidha-project/val_data.pkl')\n",
    "test_data = pd.read_pickle('/kaggle/input/suvidha-project/test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "203891f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:09:55.611401Z",
     "iopub.status.busy": "2024-01-12T10:09:55.610532Z",
     "iopub.status.idle": "2024-01-12T10:09:55.845773Z",
     "shell.execute_reply": "2024-01-12T10:09:55.844541Z"
    },
    "papermill": {
     "duration": 0.259488,
     "end_time": "2024-01-12T10:09:55.847905",
     "exception": false,
     "start_time": "2024-01-12T10:09:55.588417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 287113 entries, 0 to 287112\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   id                  287113 non-null  object\n",
      " 1   article             287113 non-null  object\n",
      " 2   highlights          287113 non-null  object\n",
      " 3   cleaned_article     287113 non-null  object\n",
      " 4   cleaned_highlights  287113 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 11.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()  # Check data types and look for anything unusual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9951004d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:09:55.892900Z",
     "iopub.status.busy": "2024-01-12T10:09:55.892038Z",
     "iopub.status.idle": "2024-01-12T10:09:55.896782Z",
     "shell.execute_reply": "2024-01-12T10:09:55.895863Z"
    },
    "papermill": {
     "duration": 0.029332,
     "end_time": "2024-01-12T10:09:55.898804",
     "exception": false,
     "start_time": "2024-01-12T10:09:55.869472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define maximum sequence lengths based on dataset summary\n",
    "max_len_article = 800  # Adjusted for the dataset\n",
    "max_len_highlights = 60  # Adjusted for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf676d64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:09:55.943416Z",
     "iopub.status.busy": "2024-01-12T10:09:55.942999Z",
     "iopub.status.idle": "2024-01-12T10:12:51.212795Z",
     "shell.execute_reply": "2024-01-12T10:12:51.211811Z"
    },
    "papermill": {
     "duration": 175.295229,
     "end_time": "2024-01-12T10:12:51.215387",
     "exception": false,
     "start_time": "2024-01-12T10:09:55.920158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "x_tokenizer = Tokenizer()\n",
    "y_tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizers on the training data\n",
    "x_tokenizer.fit_on_texts(list(train_data['cleaned_article']))\n",
    "y_tokenizer.fit_on_texts(list(train_data['cleaned_highlights']))\n",
    "\n",
    "# Convert texts to sequences and pad them\n",
    "def convert_to_sequences(data, tokenizer, max_len):\n",
    "    sequences = tokenizer.texts_to_sequences(data)\n",
    "    padded = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c87c8421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:12:51.260117Z",
     "iopub.status.busy": "2024-01-12T10:12:51.259738Z",
     "iopub.status.idle": "2024-01-12T10:12:51.264106Z",
     "shell.execute_reply": "2024-01-12T10:12:51.263237Z"
    },
    "papermill": {
     "duration": 0.028962,
     "end_time": "2024-01-12T10:12:51.266214",
     "exception": false,
     "start_time": "2024-01-12T10:12:51.237252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Pickle the tokenizers\n",
    "# import pickle\n",
    "# with open('/kaggle/input/suvidha-project/x_tokenizer.pkl', 'wb') as handle:\n",
    "#     pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('/kaggle/input/suvidha-project/y_tokenizer.pkl', 'wb') as handle:\n",
    "#     pickle.dump(y_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94214b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:12:51.309961Z",
     "iopub.status.busy": "2024-01-12T10:12:51.309041Z",
     "iopub.status.idle": "2024-01-12T10:12:52.610696Z",
     "shell.execute_reply": "2024-01-12T10:12:52.609855Z"
    },
    "papermill": {
     "duration": 1.325754,
     "end_time": "2024-01-12T10:12:52.612918",
     "exception": false,
     "start_time": "2024-01-12T10:12:51.287164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the tokenizers\n",
    "import pickle\n",
    "\n",
    "with open('/kaggle/input/suvidha-project/x_tokenizer.pkl', 'rb') as handle:\n",
    "    x_tokenizer = pickle.load(handle)\n",
    "\n",
    "with open('/kaggle/input/suvidha-project/y_tokenizer.pkl', 'rb') as handle:\n",
    "    y_tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f880d922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:12:52.657661Z",
     "iopub.status.busy": "2024-01-12T10:12:52.657314Z",
     "iopub.status.idle": "2024-01-12T10:12:52.661786Z",
     "shell.execute_reply": "2024-01-12T10:12:52.660863Z"
    },
    "papermill": {
     "duration": 0.029424,
     "end_time": "2024-01-12T10:12:52.663744",
     "exception": false,
     "start_time": "2024-01-12T10:12:52.634320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x_train = convert_to_sequences(train_data['cleaned_article'], x_tokenizer, max_len_article)\n",
    "# y_train = convert_to_sequences(train_data['cleaned_highlights'], y_tokenizer, max_len_highlights)\n",
    "\n",
    "# x_val = convert_to_sequences(validate_data['cleaned_article'], x_tokenizer, max_len_article)\n",
    "# y_val = convert_to_sequences(validate_data['cleaned_highlights'], y_tokenizer, max_len_highlights)\n",
    "\n",
    "# x_test = convert_to_sequences(test_data['cleaned_article'], x_tokenizer, max_len_article)\n",
    "# y_test = convert_to_sequences(test_data['cleaned_highlights'], y_tokenizer, max_len_highlights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "158d57d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:12:52.707261Z",
     "iopub.status.busy": "2024-01-12T10:12:52.706899Z",
     "iopub.status.idle": "2024-01-12T10:12:52.711464Z",
     "shell.execute_reply": "2024-01-12T10:12:52.710582Z"
    },
    "papermill": {
     "duration": 0.028816,
     "end_time": "2024-01-12T10:12:52.713370",
     "exception": false,
     "start_time": "2024-01-12T10:12:52.684554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming x_tokenizer and y_tokenizer are already fitted on the articles and highlights respectively\n",
    "# Define vocabulary sizes\n",
    "x_voc_size = len(x_tokenizer.word_index) + 1\n",
    "y_voc_size = len(y_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef7ec9b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:12:52.756822Z",
     "iopub.status.busy": "2024-01-12T10:12:52.756466Z",
     "iopub.status.idle": "2024-01-12T10:12:52.760997Z",
     "shell.execute_reply": "2024-01-12T10:12:52.760024Z"
    },
    "papermill": {
     "duration": 0.028504,
     "end_time": "2024-01-12T10:12:52.762995",
     "exception": false,
     "start_time": "2024-01-12T10:12:52.734491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save the tokenized and padded sequences\n",
    "# with open('/kaggle/input/suvidha-project/x_train.pkl', 'wb') as file:\n",
    "#     pickle.dump(x_train, file)\n",
    "# with open('/kaggle/input/suvidha-project/y_train.pkl', 'wb') as file:\n",
    "#     pickle.dump(y_train, file)\n",
    "# with open('/kaggle/input/suvidha-project/x_val.pkl', 'wb') as file:\n",
    "#     pickle.dump(x_val, file)\n",
    "# with open('/kaggle/input/suvidha-project/y_val.pkl', 'wb') as file:\n",
    "#     pickle.dump(y_val, file)\n",
    "# with open('/kaggle/input/suvidha-project/x_test.pkl', 'wb') as file:\n",
    "#     pickle.dump(x_test, file)\n",
    "# with open('/kaggle/input/suvidha-project/y_test.pkl', 'wb') as file:\n",
    "#     pickle.dump(y_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a37cd918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:12:52.806358Z",
     "iopub.status.busy": "2024-01-12T10:12:52.805992Z",
     "iopub.status.idle": "2024-01-12T10:12:59.185385Z",
     "shell.execute_reply": "2024-01-12T10:12:59.184453Z"
    },
    "papermill": {
     "duration": 6.403612,
     "end_time": "2024-01-12T10:12:59.187800",
     "exception": false,
     "start_time": "2024-01-12T10:12:52.784188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the tokenized and padded sequences\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('/kaggle/input/suvidha-project/x_train.pkl', 'rb') as file:\n",
    "    x_train = pickle.load(file)\n",
    "with open('/kaggle/input/suvidha-project/y_train.pkl', 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "with open('/kaggle/input/suvidha-project/x_val.pkl', 'rb') as file:\n",
    "    x_val = pickle.load(file)\n",
    "with open('/kaggle/input/suvidha-project/y_val.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "with open('/kaggle/input/suvidha-project/x_test.pkl', 'rb') as file:\n",
    "    x_test = pickle.load(file)\n",
    "with open('/kaggle/input/suvidha-project/y_test.pkl', 'rb') as file:\n",
    "    y_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c88a6",
   "metadata": {
    "papermill": {
     "duration": 0.021153,
     "end_time": "2024-01-12T10:12:59.231040",
     "exception": false,
     "start_time": "2024-01-12T10:12:59.209887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LSTM SEQ2SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b1d608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:12:59.275234Z",
     "iopub.status.busy": "2024-01-12T10:12:59.274475Z",
     "iopub.status.idle": "2024-01-12T10:13:01.449423Z",
     "shell.execute_reply": "2024-01-12T10:13:01.448494Z"
    },
    "papermill": {
     "duration": 2.199417,
     "end_time": "2024-01-12T10:13:01.451843",
     "exception": false,
     "start_time": "2024-01-12T10:12:59.252426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_len_article,))\n",
    "enc_emb = Embedding(x_voc_size, 100)(encoder_inputs)\n",
    "encoder_lstm = Bidirectional(LSTM(100, return_state=True))\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(enc_emb)\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(y_voc_size, 100)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(200, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(y_voc_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abaddae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:01.498231Z",
     "iopub.status.busy": "2024-01-12T10:13:01.497829Z",
     "iopub.status.idle": "2024-01-12T10:13:01.516474Z",
     "shell.execute_reply": "2024-01-12T10:13:01.515412Z"
    },
    "papermill": {
     "duration": 0.044446,
     "end_time": "2024-01-12T10:13:01.518790",
     "exception": false,
     "start_time": "2024-01-12T10:13:01.474344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bb06d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:01.563441Z",
     "iopub.status.busy": "2024-01-12T10:13:01.563005Z",
     "iopub.status.idle": "2024-01-12T10:13:01.571913Z",
     "shell.execute_reply": "2024-01-12T10:13:01.571044Z"
    },
    "papermill": {
     "duration": 0.033261,
     "end_time": "2024-01-12T10:13:01.574014",
     "exception": false,
     "start_time": "2024-01-12T10:13:01.540753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(self.x))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.x[inds]\n",
    "        batch_y = self.y[inds]\n",
    "        return [batch_x, batch_y], batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5133213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:01.618224Z",
     "iopub.status.busy": "2024-01-12T10:13:01.617833Z",
     "iopub.status.idle": "2024-01-12T10:13:01.623879Z",
     "shell.execute_reply": "2024-01-12T10:13:01.623139Z"
    },
    "papermill": {
     "duration": 0.030313,
     "end_time": "2024-01-12T10:13:01.625807",
     "exception": false,
     "start_time": "2024-01-12T10:13:01.595494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming x_train, y_train, x_val, y_val are your preprocessed data\n",
    "batch_size = 64  # Define your batch size\n",
    "train_gen = DataGenerator(x_train, y_train, batch_size)\n",
    "val_gen = DataGenerator(x_val, y_val, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ef746b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:01.670903Z",
     "iopub.status.busy": "2024-01-12T10:13:01.670414Z",
     "iopub.status.idle": "2024-01-12T10:13:01.676600Z",
     "shell.execute_reply": "2024-01-12T10:13:01.675679Z"
    },
    "papermill": {
     "duration": 0.031181,
     "end_time": "2024-01-12T10:13:01.678527",
     "exception": false,
     "start_time": "2024-01-12T10:13:01.647346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the checkpoint directory and file\n",
    "checkpoint_path = \"/kaggle/input/suvidha-project/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Ensure the checkpoint directory exists\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='auto',\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9a9c808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:01.723651Z",
     "iopub.status.busy": "2024-01-12T10:13:01.723283Z",
     "iopub.status.idle": "2024-01-12T10:13:01.727614Z",
     "shell.execute_reply": "2024-01-12T10:13:01.726711Z"
    },
    "papermill": {
     "duration": 0.029201,
     "end_time": "2024-01-12T10:13:01.729624",
     "exception": false,
     "start_time": "2024-01-12T10:13:01.700423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_gen,\n",
    "#     epochs=5,\n",
    "#     validation_data=val_gen,\n",
    "#     callbacks=[checkpoint_callback]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4790651d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:01.773748Z",
     "iopub.status.busy": "2024-01-12T10:13:01.773385Z",
     "iopub.status.idle": "2024-01-12T10:13:01.777585Z",
     "shell.execute_reply": "2024-01-12T10:13:01.776687Z"
    },
    "papermill": {
     "duration": 0.02825,
     "end_time": "2024-01-12T10:13:01.779549",
     "exception": false,
     "start_time": "2024-01-12T10:13:01.751299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save('/kaggle/input/suvidha-project/cnn_dailymail/seq2seq_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53203bee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:01.823456Z",
     "iopub.status.busy": "2024-01-12T10:13:01.823059Z",
     "iopub.status.idle": "2024-01-12T10:13:01.827019Z",
     "shell.execute_reply": "2024-01-12T10:13:01.826139Z"
    },
    "papermill": {
     "duration": 0.02864,
     "end_time": "2024-01-12T10:13:01.829130",
     "exception": false,
     "start_time": "2024-01-12T10:13:01.800490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_loss = model.evaluate([x_test, y_test], y_test)\n",
    "# print(f'Test Loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d6e4e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:01.873258Z",
     "iopub.status.busy": "2024-01-12T10:13:01.872881Z",
     "iopub.status.idle": "2024-01-12T10:13:14.119724Z",
     "shell.execute_reply": "2024-01-12T10:13:14.118713Z"
    },
    "papermill": {
     "duration": 12.28135,
     "end_time": "2024-01-12T10:13:14.131854",
     "exception": false,
     "start_time": "2024-01-12T10:13:01.850504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 800)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)     (None, 800, 100)             4761990   ['input_7[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  [(None, 200),                160800    ['embedding_6[0][0]']         \n",
      " al)                          (None, 100),                                                        \n",
      "                              (None, 100),                                                        \n",
      "                              (None, 100),                                                        \n",
      "                              (None, 100)]                                                        \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)     (None, None, 100)            1551580   ['input_8[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 200)                  0         ['bidirectional[0][1]',       \n",
      "                                                                     'bidirectional[0][3]']       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 200)                  0         ['bidirectional[0][2]',       \n",
      " )                                                                   'bidirectional[0][4]']       \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 200),          240800    ['embedding_7[0][0]',         \n",
      "                              (None, 200),                           'concatenate[0][0]',         \n",
      "                              (None, 200)]                           'concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, None, 155158)         3118675   ['lstm_1[0][0]']              \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 94724058 (361.34 MB)\n",
      "Trainable params: 94724058 (361.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Correct the file path by adding quotes\n",
    "model_file_path = '/kaggle/input/suvidha-project/cnn_dailymail/seq2seq_model.h5'\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model(model_file_path)\n",
    "\n",
    "# Verify the model's structure\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc9a34e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:14.185619Z",
     "iopub.status.busy": "2024-01-12T10:13:14.184855Z",
     "iopub.status.idle": "2024-01-12T10:13:14.456373Z",
     "shell.execute_reply": "2024-01-12T10:13:14.455378Z"
    },
    "papermill": {
     "duration": 0.302114,
     "end_time": "2024-01-12T10:13:14.458763",
     "exception": false,
     "start_time": "2024-01-12T10:13:14.156649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming your model's encoder and decoder LSTM units have 200 dimensions\n",
    "latent_dim = 200\n",
    "\n",
    "# Redefine the encoder model to output the states\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64c0fef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:14.509528Z",
     "iopub.status.busy": "2024-01-12T10:13:14.508846Z",
     "iopub.status.idle": "2024-01-12T10:13:14.517448Z",
     "shell.execute_reply": "2024-01-12T10:13:14.516555Z"
    },
    "papermill": {
     "duration": 0.0358,
     "end_time": "2024-01-12T10:13:14.519306",
     "exception": false,
     "start_time": "2024-01-12T10:13:14.483506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_source_word_index = x_tokenizer.word_index\n",
    "target_word_index = y_tokenizer.word_index\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_word_index.get('starttoken', 1)\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "\n",
    "        if sampled_token_index in reverse_target_word_index:\n",
    "            sampled_word = reverse_target_word_index[sampled_token_index]\n",
    "        else:\n",
    "            sampled_word = 'UNK'  # Using 'UNK' for unknown words\n",
    "\n",
    "        if sampled_word == 'endtoken' or len(decoded_sentence) > max_len_article:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b0da16a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:14.569359Z",
     "iopub.status.busy": "2024-01-12T10:13:14.568634Z",
     "iopub.status.idle": "2024-01-12T10:13:14.573446Z",
     "shell.execute_reply": "2024-01-12T10:13:14.572546Z"
    },
    "papermill": {
     "duration": 0.031981,
     "end_time": "2024-01-12T10:13:14.575453",
     "exception": false,
     "start_time": "2024-01-12T10:13:14.543472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # Define the number of samples to decode\n",
    "# num_samples_to_decode = 50  # Adjust this number as needed\n",
    "\n",
    "# # Randomly select indices for the subset\n",
    "# random_indices = random.sample(range(len(x_test)), min(num_samples_to_decode, len(x_test)))\n",
    "\n",
    "# # Generate and save decoded sentences and original summaries for the random subset\n",
    "# decoded_sentences = []\n",
    "# original_summaries = []\n",
    "\n",
    "# for i in random_indices:\n",
    "#     input_seq = x_test[i].reshape(1, -1)\n",
    "#     decoded_sentence = decode_sequence(input_seq)\n",
    "#     decoded_sentences.append(decoded_sentence)\n",
    "#     original_summaries.append(y_test[i])  # Assuming y_test contains the actual summaries\n",
    "\n",
    "# # ... code to pickle decoded_sentences and original_summaries ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f656624a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:14.627435Z",
     "iopub.status.busy": "2024-01-12T10:13:14.627054Z",
     "iopub.status.idle": "2024-01-12T10:13:14.631806Z",
     "shell.execute_reply": "2024-01-12T10:13:14.630822Z"
    },
    "papermill": {
     "duration": 0.033282,
     "end_time": "2024-01-12T10:13:14.633787",
     "exception": false,
     "start_time": "2024-01-12T10:13:14.600505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# File paths for saving\n",
    "decoded_sentences_file = '/kaggle/input/decoded/decoded_sentences.pkl'\n",
    "original_summaries_file = '/kaggle/input/decoded/original_summaries.pkl'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc760902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:14.684780Z",
     "iopub.status.busy": "2024-01-12T10:13:14.684426Z",
     "iopub.status.idle": "2024-01-12T10:13:14.688619Z",
     "shell.execute_reply": "2024-01-12T10:13:14.687807Z"
    },
    "papermill": {
     "duration": 0.031692,
     "end_time": "2024-01-12T10:13:14.690474",
     "exception": false,
     "start_time": "2024-01-12T10:13:14.658782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save decoded sentences\n",
    "# with open(decoded_sentences_file, 'wb') as file:\n",
    "#     pickle.dump(decoded_sentences, file)\n",
    "\n",
    "# # Save original summaries\n",
    "# with open(original_summaries_file, 'wb') as file:\n",
    "#     pickle.dump(original_summaries, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "648e2406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:14.742429Z",
     "iopub.status.busy": "2024-01-12T10:13:14.742036Z",
     "iopub.status.idle": "2024-01-12T10:13:14.752421Z",
     "shell.execute_reply": "2024-01-12T10:13:14.751685Z"
    },
    "papermill": {
     "duration": 0.038216,
     "end_time": "2024-01-12T10:13:14.754484",
     "exception": false,
     "start_time": "2024-01-12T10:13:14.716268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load decoded sentences\n",
    "with open(decoded_sentences_file, 'rb') as file:\n",
    "    decoded_sentences = pickle.load(file)\n",
    "\n",
    "# Load original summaries\n",
    "with open(original_summaries_file, 'rb') as file:\n",
    "    original_summaries = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f49da0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:14.805102Z",
     "iopub.status.busy": "2024-01-12T10:13:14.804379Z",
     "iopub.status.idle": "2024-01-12T10:13:14.809220Z",
     "shell.execute_reply": "2024-01-12T10:13:14.808311Z"
    },
    "papermill": {
     "duration": 0.032367,
     "end_time": "2024-01-12T10:13:14.811536",
     "exception": false,
     "start_time": "2024-01-12T10:13:14.779169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the first summary: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Check the type of the first element (if the list is not empty)\n",
    "if original_summaries:\n",
    "    print(f\"Type of the first summary: {type(original_summaries[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bb6261c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:14.862296Z",
     "iopub.status.busy": "2024-01-12T10:13:14.861384Z",
     "iopub.status.idle": "2024-01-12T10:13:14.866842Z",
     "shell.execute_reply": "2024-01-12T10:13:14.865845Z"
    },
    "papermill": {
     "duration": 0.033782,
     "end_time": "2024-01-12T10:13:14.868896",
     "exception": false,
     "start_time": "2024-01-12T10:13:14.835114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the first decoded summary: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "if decoded_sentences:\n",
    "    print(f\"Type of the first decoded summary: {type(decoded_sentences[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b489eb7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:14.920136Z",
     "iopub.status.busy": "2024-01-12T10:13:14.919428Z",
     "iopub.status.idle": "2024-01-12T10:13:14.968792Z",
     "shell.execute_reply": "2024-01-12T10:13:14.967977Z"
    },
    "papermill": {
     "duration": 0.076809,
     "end_time": "2024-01-12T10:13:14.970793",
     "exception": false,
     "start_time": "2024-01-12T10:13:14.893984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seq_to_text(sequence, tokenizer):\n",
    "    word_index = tokenizer.index_word\n",
    "    return ' '.join([word_index.get(i, '?') for i in sequence if i != 0])  # Replace 0 with your tokenizer's padding token index, if different\n",
    "\n",
    "# Convert original summaries from sequences to text\n",
    "text_original_summaries = [seq_to_text(summary, y_tokenizer) for summary in original_summaries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04e52f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:15.020714Z",
     "iopub.status.busy": "2024-01-12T10:13:15.020375Z",
     "iopub.status.idle": "2024-01-12T10:13:15.025240Z",
     "shell.execute_reply": "2024-01-12T10:13:15.024340Z"
    },
    "papermill": {
     "duration": 0.031843,
     "end_time": "2024-01-12T10:13:15.027122",
     "exception": false,
     "start_time": "2024-01-12T10:13:14.995279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if original_summaries and isinstance(original_summaries[0], bytes):\n",
    "    original_summaries = [summary.decode('utf-8') for summary in original_summaries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d4ad6a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:15.077537Z",
     "iopub.status.busy": "2024-01-12T10:13:15.077162Z",
     "iopub.status.idle": "2024-01-12T10:13:15.164291Z",
     "shell.execute_reply": "2024-01-12T10:13:15.163467Z"
    },
    "papermill": {
     "duration": 0.115739,
     "end_time": "2024-01-12T10:13:15.166623",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.050884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "processed_decoded_summaries = [' '.join(word_tokenize(summary)) for summary in decoded_sentences]\n",
    "processed_original_summaries = [' '.join(word_tokenize(summary)) for summary in text_original_summaries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "216bf7ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:15.216282Z",
     "iopub.status.busy": "2024-01-12T10:13:15.215893Z",
     "iopub.status.idle": "2024-01-12T10:13:15.224483Z",
     "shell.execute_reply": "2024-01-12T10:13:15.223563Z"
    },
    "papermill": {
     "duration": 0.036438,
     "end_time": "2024-01-12T10:13:15.227277",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.190839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   381   2570    109    822   2639   1151      2     24    455   2503\n",
      "      4   2503     15   2540   1343      5     55    337      2      1\n",
      "   6232     84   1000     28   4213     70    257    161   3140     49\n",
      "   3231     12   1477   1037     18    630     30    142      9      1\n",
      "  12441    692     11  32814     12     35     98   5461     14      7\n",
      "   1477     99    249      4    674      6   2086     51     68  31929\n",
      "     71      1   1757    901  12441    692     11   3231   1477     99\n",
      "    249      4    674      6   2086     32    137      3    125      7\n",
      "   3342   7398    199    213     48     21      1    405      5   3365\n",
      "     16     18      3    201    771      9     90      1    140     12\n",
      "    651      2    213   1848     10   1211   1503     11   3231     14\n",
      "    584     42  34525      3   3024   1188      5    692     10   2647\n",
      "      6      3     93     94   1211     22     51    520      2    692\n",
      "      4    418     68   2647     16   2667 162163   3342   3555     11\n",
      "      1    941     14     12     62      9      1   9765      4   6582\n",
      "    136      3    867     10  10312    658      5   1037     27     80\n",
      "  30005     11   3231    615      2     51    701    878     68    936\n",
      "     10    692      6      1   8567  29043   6252  20336      4   1616\n",
      "     92   5212   1646   2494     21      1   6582    250   3231     15\n",
      "      3   1124   3044   1947      3   2042     46     11     84   1985\n",
      "     25  12167    116   1177   2639     11    168   1985     22    318\n",
      "   2533      5    485     90     84   1985   1032     19    262     19\n",
      "    861   2533  12251      3    530   3809   5464     15      1    627\n",
      "   3554    980      9     14  19481   1646     11    109    967   1037\n",
      "     59    569      3    822     27    154   1646     28   2494    359\n",
      "   3231     15   1124   2533    169    265   1586      5   2639      3\n",
      "   2042     46     11     84   1985     25  12167    280      1   4029\n",
      "    217      1   2522    169     58   2639     23     43    414     11\n",
      "      3   1616      2      1    209    414     11      1   1616    361\n",
      "     14     12    284     19      1   1947     90    111   1985   3136\n",
      "      2      3   1947      5   1124   2533     52    704     84   1093\n",
      "   1526     32     90    168   1985     25    318   2533      5    692\n",
      "   2968    400   1177   2639     22    169    959      4   1409   2533\n",
      "    400   2668   2016    959   2533      4   2819   1985   2016     66\n",
      "    861   2533    267   4998     25      3   1616   1947      5   1124\n",
      "   2533     90  13440     25    959   2533   9324      7    777   5536\n",
      "   1616   1947     12    861   2533      4   4338   3069      7     12\n",
      "    318   1124      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n",
      "[  459  1498   110  4196    46  2423    27  2525   772    14   689    69\n",
      "     7  4000  9201   139    19  3053   787   332    26 34155   700  1119\n",
      "  3722    10  2423    13    47  1055   663    64  1609   976     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0])  # Inspect the first preprocessed test sample\n",
    "print(y_test[0])  # Inspect the first actual test label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "291f19a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:15.277969Z",
     "iopub.status.busy": "2024-01-12T10:13:15.277608Z",
     "iopub.status.idle": "2024-01-12T10:13:15.410590Z",
     "shell.execute_reply": "2024-01-12T10:13:15.409630Z"
    },
    "papermill": {
     "duration": 0.160864,
     "end_time": "2024-01-12T10:13:15.412826",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.251962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
      "Average BLEU Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "rouge = Rouge()\n",
    "rouge_scores = rouge.get_scores(processed_decoded_summaries, processed_original_summaries, avg=True)\n",
    "\n",
    "# Calculate BLEU scores\n",
    "bleu_scores = [sentence_bleu([ref.split()], hyp.split(), smoothing_function=SmoothingFunction().method1)\n",
    "               for ref, hyp in zip(processed_original_summaries, processed_decoded_summaries)]\n",
    "avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "# Print the scores\n",
    "print(\"ROUGE Scores:\", rouge_scores)\n",
    "print(\"Average BLEU Score:\", avg_bleu_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54e63a79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:15.464529Z",
     "iopub.status.busy": "2024-01-12T10:13:15.463674Z",
     "iopub.status.idle": "2024-01-12T10:13:15.469631Z",
     "shell.execute_reply": "2024-01-12T10:13:15.468696Z"
    },
    "papermill": {
     "duration": 0.033914,
     "end_time": "2024-01-12T10:13:15.472053",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.438139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:  pedropsa torkham fuglesang forbidden eurorap comminty comminty chelios twc twc dower persuasive veneman\n",
      "Original summary: collette dinnigan s paddington 6 million home has hit the market she and her husband bradley cocks paid 4 45 million for it back in 2009 the luxury house will go under the hammer on may 23 the four bedroom two storey sandstone property was built in 1880 the fashionista and her husband have carefully renovated the property\n",
      "\n",
      "\n",
      "Generated summary:  daringly denunciations majene rennard gonzales zamost exersice innocuous hitchhike hitchhike espen 1979\n",
      "Original summary: abby has a rare genetic syndrome and has cataracts as a result her mother amanda said she has no vision at all without her glasses felt her daughter had been discriminated against when she found out other children at abby s school got to wear their glasses school photography has since apologized and will re take abby s picture for free\n",
      "\n",
      "\n",
      "Generated summary:  mcpartlin clarksville eyesee 3dsd chesmore pembleton balms ferreyra balms mutlaq norlaila kubiak szczecin\n",
      "Original summary: gupta is in kathmandu to cover the aftermath of deadly earthquake the hospitals are so overstretched that he was asked to perform brain surgery on a teenager who had been crushed by a wall in the quake he said the girl is now doing well but she is just one of many victims 4 352 people are believed to have died including at least four americans and more than 6 000 suffered injuries\n",
      "\n",
      "\n",
      "Generated summary:  refiles broner broner sokratis kinsmann contortion advocacy changaris ease ease bss polishes 173lbs 173lbs\n",
      "Original summary: toby huntington whiteley 25 and cricketer flintoff 37 model in campaign men s clothing brand jacamo caters to larger and taller men sportsman flintoff has been face of brand for 4 years this is second tv ad job for dorset boy toby\n",
      "\n",
      "\n",
      "Generated summary:  rhimes rhimes rhimes rhimes rhimes rhimes rhimes rhimes urbandata urbandata bamboo ununpentium aoc aoc\n",
      "Original summary: hilary border 54 pleaded guilty to fraud and has been spared jail she stole 20 000 from dementia stricken mother and spent it on herself mother of three refused to pay 16 000 in care home bills for dorothy 83 she has been spared jail and ordered to carry out 150 hours of unpaid work\n",
      "\n",
      "\n",
      "Generated summary:  vento conflagration tonopah transpiration superclusters eavesdropping daltrey kayleigh dexetra expeditions\n",
      "Original summary: graffiti artists work through the night to repaint 30 telephone booths latest in series of themed stunts as character craze sweeps china artists wanted to help burned out beijing residents feel less stressed\n",
      "\n",
      "\n",
      "Generated summary:  martins bili councilor zedd nagore manithon encodes boers dsquared2 crosshouse bensalem bromborough tillig\n",
      "Original summary: billy anne huxham was abducted from her caboolture home on tuesday she was located on thursday night by police on aerodrome road she was allegedly taken by 32 year old ex boyfriend carl garry chapman chapman was reportedly carrying a firearm when he was apprehended he has been charged with a string of offences including torture and assault chapman who was out on bail is due to face the magistrate on saturday\n",
      "\n",
      "\n",
      "Generated summary:  poertschach poertschach buzby dominate starkiller starkiller triumvirate utilize utilize scrappage ampthill\n",
      "Original summary: marcus a 13 year old maryland boy provided firefighters with instructions smelled smoke when family s clinton home caught fire sunday morning was trapped in a second floor bedroom with nine year old sister during fire soothed his sister after she blurted out we re going to die during the call siblings saved and three other people in the home escaped without injury\n",
      "\n",
      "\n",
      "Generated summary:  leoti leoti arribadas leoti arribadas travelled stecki obseinogenic degenkolb brighthaupt florentina\n",
      "Original summary: aboriginal model management australia has 40 female clients so far new national casting call is now looking for both sexes aged up to 60 founder is expecting the numbers to take off as interest rapidly grows target bonds and big w are very interested in hiring aboriginal models kira lea says demand for indigenous models is slowly changing in the high fashion market but should be moving faster\n",
      "\n",
      "\n",
      "Generated summary:  toven countertenor capote 23secs blueberries blueberries sumptuous kronfield globemaster globemaster\n",
      "Original summary: new indiana law no one has the legal right to refuse to offer or provide goods services facilities or employment to anyone in previously protected classes or based on sexual orientation or gender identity it was never intended to discriminate against anyone indiana senate president pro tem david long said this morning at a press conference arkansas legislature also passed changes to its legislation at the behest of the state s republican governor asa hutchinson altered law more closely mirror federal legislation it passed the senate last night and is now under consideration in the house\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Generated summary:\", decoded_sentences[i])\n",
    "    print(\"Original summary:\", text_original_summaries[i])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad4e7d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:15.526821Z",
     "iopub.status.busy": "2024-01-12T10:13:15.526104Z",
     "iopub.status.idle": "2024-01-12T10:13:15.536441Z",
     "shell.execute_reply": "2024-01-12T10:13:15.535479Z"
    },
    "papermill": {
     "duration": 0.039389,
     "end_time": "2024-01-12T10:13:15.538898",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.499509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original summary: [ 32433 110284      7  13969    217    133     68     16    197      1\n",
      "    902     25      6     20    256   3471  55082    539    195    990\n",
      "    133      8     22     88      3    664      1   1659    121     28\n",
      "    223    151      1   4551     10    114    508      1     87   1606\n",
      "     41   5520  21897    743      9    870      3  26797      1  41016\n",
      "      6     20    256     24   8524  13080      1    743      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n",
      "Generated summary:  pedropsa torkham fuglesang forbidden eurorap comminty comminty chelios twc twc dower persuasive veneman\n",
      "\n",
      "\n",
      "Original summary: [11179    16     5  1122  4218  2506     6    16 31888    21     5  1130\n",
      "    20   103  2930    35    25    16    73  4107    14    80   308    20\n",
      "  5328  1462    20   218    37    33 15099    81    56    25    60    46\n",
      "    95    98    14 11179     7   131   381     2  1687    40  5328   131\n",
      "  5758    16    91  3570     6    28   443   137 11179     7  1021     8\n",
      "   377     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "Generated summary:  daringly denunciations majene rennard gonzales zamost exersice innocuous hitchhike hitchhike espen 1979\n",
      "\n",
      "\n",
      "Original summary: [ 9389    11     3 24856     2  1177     1  6498     4  1828  3616     1\n",
      "  2378    27   152 39470    29    12     9   417     2  2601   786   628\n",
      "    10     5  1181    48    37    33  5015    18     5  1354     3     1\n",
      "  3504    12    35     1   307    11    66  1251   375    32    25    11\n",
      "    92    43     4   185   448   195 32734    59    27   429     2    24\n",
      "    99   237    14   336    87   719     6    47    64   217    53   371\n",
      "   514     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "Generated summary:  mcpartlin clarksville eyesee 3dsd chesmore pembleton balms ferreyra balms mutlaq norlaila kubiak szczecin\n",
      "\n",
      "\n",
      "Original summary: [ 8787 13674 16178   294     6  9661 14041  1301   814     3   374   148\n",
      "     7  2852  1555 73965 18612     2  3110     6 12578   148 15491 14041\n",
      "    16    33   156     4  1555     8   195    52    51    11   129   416\n",
      "  2018   519     8  4212   347  8787     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "Generated summary:  refiles broner broner sokratis kinsmann contortion advocacy changaris ease ease bss polishes 173lbs 173lbs\n",
      "\n",
      "\n",
      "Original summary: [10172  1001  1911  1026   343     2  1575     6    16    33  6081   535\n",
      "    25  1856   162    53    17  4479  6595   103     6   337    22    10\n",
      "  1218   103     4    65   783     2   324   284    53     3   410    68\n",
      "  2513     8  9357  4226    25    16    33  6081   535     6   895     2\n",
      "  1558    46  1530   215     4  4979   174     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "Generated summary:  rhimes rhimes rhimes rhimes rhimes rhimes rhimes rhimes urbandata urbandata bamboo ununpentium aoc aoc\n",
      "\n",
      "\n",
      "Original summary: [ 6757  3152   174   169     1   181     2 44772   208  8043 21728   624\n",
      "     3   518     4  5322 10434    21  1941  7934 17559   344  3152   449\n",
      "     2   141  2736    46  2515   755  1207   551  7381     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "Generated summary:  vento conflagration tonopah transpiration superclusters eavesdropping daltrey kayleigh dexetra expeditions\n",
      "\n",
      "\n",
      "Original summary: [  4194   3097 117289      9   3823     17     20  49893     68     10\n",
      "    253     25      9   2928     10    334    181     18     44     10\n",
      "  33095    611     25      9    302    192     18    793     30     45\n",
      "    408    946   3897   7568   7070   7070      9    696   1371      5\n",
      "   6681     56     12      9  10635     12     16     33    200     13\n",
      "      5   2864      4   2230    237   3394      6    608   7070     48\n",
      "      9     46     10   1431     11    286      2    156      1   9484\n",
      "     10    211      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n",
      "Generated summary:  martins bili councilor zedd nagore manithon encodes boers dsquared2 crosshouse bensalem bromborough tillig\n",
      "\n",
      "\n",
      "Original summary: [ 7165     5   380    30    45  3443   347  2740  2193    13  7193 14938\n",
      "  2480    56    83     7   815    68   593   281   194   467     9  2310\n",
      "     3     5   129  1449  1606    13   496    30    45   822    93   281\n",
      " 78215    15   822    23    25 45848    46   175   443   444     2  1219\n",
      "    93     1   387  4464  1864     6    65    95    59     3     1    68\n",
      "  1748   308   548     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "Generated summary:  poertschach poertschach buzby dominate starkiller starkiller triumvirate utilize utilize scrappage ampthill\n",
      "\n",
      "\n",
      "Original summary: [15256   814  2641   460    16   384   745  3796   152   619    31   250\n",
      "  9264   387    11    66   565     8   190 17106   670    42     2   695\n",
      "  1758    11  4507     1  1710     2   137    79    21  1191  7246  7360\n",
      "  1126  9935     6   447  3321    27   506  2272     3  6496 15256  1968\n",
      " 30432 15282    19  1842     8  7910  1968    11  5592  2490     3     1\n",
      "   164  1306   902    32   184    26  1505  4074     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "Generated summary:  leoti leoti arribadas leoti arribadas travelled stecki obseinogenic degenkolb brighthaupt florentina\n",
      "\n",
      "\n",
      "Original summary: [   31  3392   320    73    43    16     1   644   433     2  4710     2\n",
      "   976    78  1426  3465   932  4137    78  5220     2  1587     3   817\n",
      "  4338  3618    78   457    10   614 10570    78  3274  2478    22     9\n",
      "   335  3084     2 18627    81  1587  3392  1206   107  1650 70875   202\n",
      "   231    35    51   467    14     5  1369  1383  4591 12553    49  1163\n",
      "  1261     2    85  2886    14     1 45005     4     1   134     7  1397\n",
      "  1300 16715 15787  8329   320    47  5623  5619   707  2886    22  1163\n",
      "     1  1206    54   181     6    11    66   151 10014     3     1   121\n",
      "     0     0     0     0]\n",
      "Generated summary:  toven countertenor capote 23secs blueberries blueberries sumptuous kronfield globemaster globemaster\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Original summary:\", original_summaries[i])\n",
    "    print(\"Generated summary:\", decoded_sentences[i])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165215f",
   "metadata": {
    "papermill": {
     "duration": 0.024523,
     "end_time": "2024-01-12T10:13:15.588002",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.563479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multi-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40dac14a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:15.639555Z",
     "iopub.status.busy": "2024-01-12T10:13:15.638655Z",
     "iopub.status.idle": "2024-01-12T10:13:15.643033Z",
     "shell.execute_reply": "2024-01-12T10:13:15.642179Z"
    },
    "papermill": {
     "duration": 0.032143,
     "end_time": "2024-01-12T10:13:15.644959",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.612816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, GRU, Dense, Embedding\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1f27759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:15.697941Z",
     "iopub.status.busy": "2024-01-12T10:13:15.697552Z",
     "iopub.status.idle": "2024-01-12T10:13:15.706416Z",
     "shell.execute_reply": "2024-01-12T10:13:15.705488Z"
    },
    "papermill": {
     "duration": 0.038496,
     "end_time": "2024-01-12T10:13:15.708384",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.669888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Check available GPUs\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         # Enable GPU memory growth\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "#         # Create a MirroredStrategy\n",
    "#         strategy = tf.distribute.MirroredStrategy()\n",
    "#         print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "#         # Open a strategy scope\n",
    "#         with strategy.scope():\n",
    "#             # Encoder\n",
    "#             encoder_inputs = Input(shape=(max_len_text,))\n",
    "#             enc_emb = Embedding(x_voc_size, 100)(encoder_inputs)\n",
    "#             encoder_lstm = Bidirectional(LSTM(100, return_state=True))\n",
    "#             encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(enc_emb)\n",
    "#             state_h = Concatenate()([forward_h, backward_h])\n",
    "#             state_c = Concatenate()([forward_c, backward_c])\n",
    "#             encoder_states = [state_h, state_c]\n",
    "\n",
    "#             # Decoder\n",
    "#             decoder_inputs = Input(shape=(None,))\n",
    "#             dec_emb_layer = Embedding(y_voc_size, 100)\n",
    "#             dec_emb = dec_emb_layer(decoder_inputs)\n",
    "#             decoder_lstm = LSTM(200, return_sequences=True, return_state=True)\n",
    "#             decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "#             decoder_dense = Dense(y_voc_size, activation='softmax')\n",
    "#             decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "#             # Define the model\n",
    "#             model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "            \n",
    "#             model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "            \n",
    "#             from tensorflow.keras.utils import Sequence\n",
    "\n",
    "#             class DataGenerator(Sequence):\n",
    "#                 def __init__(self, x_set, y_set, batch_size):\n",
    "#                     self.x, self.y = x_set, y_set\n",
    "#                     self.batch_size = batch_size\n",
    "#                     self.indices = np.arange(len(self.x))\n",
    "\n",
    "#                 def __len__(self):\n",
    "#                     return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "#                 def __getitem__(self, idx):\n",
    "#                     inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "#                     batch_x = self.x[inds]\n",
    "#                     batch_y = self.y[inds]\n",
    "#                     return [batch_x, batch_y], batch_y\n",
    "\n",
    "#                 def on_epoch_end(self):\n",
    "#                     np.random.shuffle(self.indices)\n",
    "                    \n",
    "#             # Assuming x_train, y_train, x_val, y_val are your preprocessed data\n",
    "#             batch_size = 64  # Define your batch size\n",
    "#             train_gen = DataGenerator(x_train, y_train, batch_size)\n",
    "#             val_gen = DataGenerator(x_val, y_val, batch_size)\n",
    "            \n",
    "#             # Set up the checkpoint directory and file\n",
    "#             checkpoint_path = \"/kaggle/working/cnn_dailymail/cp.ckpt\"\n",
    "#             checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "#             # Ensure the checkpoint directory exists\n",
    "#             os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "#             # ModelCheckpoint callback\n",
    "#             checkpoint_callback = ModelCheckpoint(\n",
    "#                 filepath=checkpoint_path,\n",
    "#                 monitor='val_loss',\n",
    "#                 verbose=1,\n",
    "#                 save_best_only=True,\n",
    "#                 save_weights_only=True,\n",
    "#                 mode='auto',\n",
    "#                 save_freq='epoch'\n",
    "#             )\n",
    "            \n",
    "#             history = model.fit(\n",
    "#             train_gen,\n",
    "#             epochs=5,\n",
    "#             validation_data=val_gen,\n",
    "#             callbacks=[checkpoint_callback]\n",
    "#         )\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "# else:\n",
    "#     print('No GPUs available.')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4345ddf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:15.760885Z",
     "iopub.status.busy": "2024-01-12T10:13:15.760506Z",
     "iopub.status.idle": "2024-01-12T10:13:15.764706Z",
     "shell.execute_reply": "2024-01-12T10:13:15.763766Z"
    },
    "papermill": {
     "duration": 0.032745,
     "end_time": "2024-01-12T10:13:15.766673",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.733928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save('/kaggle/working/cnn_dailymail/seq2seq_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ea670",
   "metadata": {
    "papermill": {
     "duration": 0.025136,
     "end_time": "2024-01-12T10:13:15.817887",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.792751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GRU****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c3faaae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:15.870327Z",
     "iopub.status.busy": "2024-01-12T10:13:15.869570Z",
     "iopub.status.idle": "2024-01-12T10:13:18.898964Z",
     "shell.execute_reply": "2024-01-12T10:13:18.898088Z"
    },
    "papermill": {
     "duration": 3.058763,
     "end_time": "2024-01-12T10:13:18.901594",
     "exception": false,
     "start_time": "2024-01-12T10:13:15.842831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Embedding\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# # Define maximum sequence lengths based on dataset summary\n",
    "# max_len_article = 800  # Adjusted for the dataset\n",
    "# max_len_highlights = 60  # Adjusted for the dataset\n",
    "\n",
    "# # Assuming x_tokenizer and y_tokenizer are already fitted on the articles and highlights respectively\n",
    "# # Define vocabulary sizes\n",
    "# x_voc_size = len(x_tokenizer.word_index) + 1\n",
    "# y_voc_size = len(y_tokenizer.word_index) + 1\n",
    "\n",
    "# Pad the sequences to the max length for articles\n",
    "x_train_padded = pad_sequences(x_train, maxlen=max_len_article, padding='post')\n",
    "x_val_padded = pad_sequences(x_val, maxlen=max_len_article, padding='post')\n",
    "\n",
    "# Add a start token to the beginning of each target sequence and end token at the end\n",
    "start_token = 1\n",
    "end_token = 2\n",
    "\n",
    "# Assuming y_train and y_val already contain end tokens, we need to add start tokens\n",
    "y_train_with_start = np.hstack([np.full((y_train.shape[0], 1), start_token), y_train])\n",
    "y_val_with_start = np.hstack([np.full((y_val.shape[0], 1), start_token), y_val])\n",
    "\n",
    "# Ensure the sequences are of length 100, you might need to truncate or pad accordingly\n",
    "y_train_padded = pad_sequences(y_train_with_start, maxlen=max_len_highlights, padding='post', truncating='post')\n",
    "y_val_padded = pad_sequences(y_val_with_start, maxlen=max_len_highlights, padding='post', truncating='post')\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_len_article,))\n",
    "encoder_embedding = Embedding(input_dim=x_voc_size, output_dim=100)(encoder_inputs)\n",
    "encoder_gru = GRU(100, return_state=True)\n",
    "encoder_outputs, encoder_state = encoder_gru(encoder_embedding)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_len_highlights-1,))  # -1 because we shift the decoder inputs and outputs\n",
    "decoder_embedding = Embedding(input_dim=y_voc_size, output_dim=100)(decoder_inputs)\n",
    "decoder_gru = GRU(100, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _ = decoder_gru(decoder_embedding, initial_state=encoder_state)\n",
    "decoder_dense = Dense(y_voc_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c82a32c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:18.958991Z",
     "iopub.status.busy": "2024-01-12T10:13:18.958594Z",
     "iopub.status.idle": "2024-01-12T10:13:18.979196Z",
     "shell.execute_reply": "2024-01-12T10:13:18.978111Z"
    },
    "papermill": {
     "duration": 0.050924,
     "end_time": "2024-01-12T10:13:18.981358",
     "exception": false,
     "start_time": "2024-01-12T10:13:18.930434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting training from scratch.\n"
     ]
    }
   ],
   "source": [
    "# Define the model that will turn encoder_input_data & decoder_input_data into decoder_target_data\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint_path = \"/kaggle/working/checkpoints_gru/ckpt_{epoch}\"\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Define the checkpoint directory\n",
    "checkpoint_dir = \"/kaggle/working/checkpoints_gru\"\n",
    "\n",
    "# Load the latest checkpoint\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "initial_epoch = 0\n",
    "if latest_checkpoint:\n",
    "    print(f\"Loading weights from {latest_checkpoint}\")\n",
    "    model.load_weights(latest_checkpoint)\n",
    "\n",
    "    # Extract the epoch number from the filename\n",
    "    checkpoint_name = os.path.basename(latest_checkpoint)\n",
    "    checkpoint_epoch = checkpoint_name.split('_')[-1]\n",
    "    initial_epoch = int(checkpoint_epoch)\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0bbbc35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:19.036697Z",
     "iopub.status.busy": "2024-01-12T10:13:19.036329Z",
     "iopub.status.idle": "2024-01-12T10:13:19.041018Z",
     "shell.execute_reply": "2024-01-12T10:13:19.040106Z"
    },
    "papermill": {
     "duration": 0.03469,
     "end_time": "2024-01-12T10:13:19.043119",
     "exception": false,
     "start_time": "2024-01-12T10:13:19.008429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Train the model with the correct shapes\n",
    "# history = model.fit(\n",
    "#     [x_train_padded, y_train_padded[:,:-1]],\n",
    "#     y_train_padded.reshape(y_train_padded.shape[0], y_train_padded.shape[1], 1)[:,1:],\n",
    "#     initial_epoch=initial_epoch,\n",
    "#     epochs=5,\n",
    "#     batch_size=64,\n",
    "#     validation_data=(\n",
    "#         [x_val_padded, y_val_padded[:,:-1]],\n",
    "#         y_val_padded.reshape(y_val_padded.shape[0], y_val_padded.shape[1], 1)[:,1:]\n",
    "#     ),\n",
    "#     callbacks=[checkpoint_callback]\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f1c7ae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:19.097824Z",
     "iopub.status.busy": "2024-01-12T10:13:19.097436Z",
     "iopub.status.idle": "2024-01-12T10:13:25.705543Z",
     "shell.execute_reply": "2024-01-12T10:13:25.704600Z"
    },
    "papermill": {
     "duration": 6.638292,
     "end_time": "2024-01-12T10:13:25.707757",
     "exception": false,
     "start_time": "2024-01-12T10:13:19.069465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /kaggle/working/final_gru_model\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model after training\n",
    "model_save_path = \"/kaggle/working/final_gru_model\"\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eed57628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:25.760477Z",
     "iopub.status.busy": "2024-01-12T10:13:25.760061Z",
     "iopub.status.idle": "2024-01-12T10:13:32.084724Z",
     "shell.execute_reply": "2024-01-12T10:13:32.083593Z"
    },
    "papermill": {
     "duration": 6.353334,
     "end_time": "2024-01-12T10:13:32.086907",
     "exception": false,
     "start_time": "2024-01-12T10:13:25.733573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Path to the saved model directory\n",
    "model_load_path = \"/kaggle/input/suvidha-project/final_gru_model\"  # Update with your actual path\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model(model_load_path)\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Now you can use loaded_model to make predictions, evaluate, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "615df5df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:32.140901Z",
     "iopub.status.busy": "2024-01-12T10:13:32.140035Z",
     "iopub.status.idle": "2024-01-12T10:13:32.170640Z",
     "shell.execute_reply": "2024-01-12T10:13:32.169548Z"
    },
    "papermill": {
     "duration": 0.065542,
     "end_time": "2024-01-12T10:13:32.177870",
     "exception": false,
     "start_time": "2024-01-12T10:13:32.112328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 800)]                0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 59)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 800, 100)             4761990   ['input_5[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 59, 100)              1551580   ['input_6[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " gru (GRU)                   [(None, 100),                60600     ['embedding_2[0][0]']         \n",
      "                              (None, 100)]                                                        \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                 [(None, 59, 100),            60600     ['embedding_3[0][0]',         \n",
      "                              (None, 100)]                           'gru[0][1]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 59, 155158)           1567095   ['gru_1[0][0]']               \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 78927858 (301.09 MB)\n",
      "Trainable params: 78927858 (301.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe770211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T05:22:41.129596Z",
     "iopub.status.busy": "2024-01-12T05:22:41.129195Z",
     "iopub.status.idle": "2024-01-12T05:22:41.134478Z",
     "shell.execute_reply": "2024-01-12T05:22:41.133410Z",
     "shell.execute_reply.started": "2024-01-12T05:22:41.129565Z"
    },
    "papermill": {
     "duration": 0.026922,
     "end_time": "2024-01-12T10:13:32.232316",
     "exception": false,
     "start_time": "2024-01-12T10:13:32.205394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e2dff41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:32.288494Z",
     "iopub.status.busy": "2024-01-12T10:13:32.288135Z",
     "iopub.status.idle": "2024-01-12T10:13:33.862410Z",
     "shell.execute_reply": "2024-01-12T10:13:33.861402Z"
    },
    "papermill": {
     "duration": 1.605484,
     "end_time": "2024-01-12T10:13:33.864890",
     "exception": false,
     "start_time": "2024-01-12T10:13:32.259406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "sample_size = 10 # Try with an even smaller number of samples\n",
    "x_test_sample = x_val_padded[:sample_size]\n",
    "y_test_sample = y_val_padded[:sample_size, :-1]\n",
    "\n",
    "sample_predictions = model.predict([x_test_sample, y_test_sample])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab6e4ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:33.922037Z",
     "iopub.status.busy": "2024-01-12T10:13:33.921298Z",
     "iopub.status.idle": "2024-01-12T10:13:33.977473Z",
     "shell.execute_reply": "2024-01-12T10:13:33.976280Z"
    },
    "papermill": {
     "duration": 0.087344,
     "end_time": "2024-01-12T10:13:33.979860",
     "exception": false,
     "start_time": "2024-01-12T10:13:33.892516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding sequences: 100%|██████████| 10/10 [00:00<00:00, 11205.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def decode_sequence(input_sequence, tokenizer):\n",
    "    text = ''\n",
    "    for i in input_sequence:\n",
    "        if (i != 0):  # skipping the padding (0)\n",
    "            text += tokenizer.index_word[i] + ' '\n",
    "    return text.strip()\n",
    "\n",
    "# Choose the size of the subset you want to decode\n",
    "subset_size = 100  # For example, decode only the first 100 sequences\n",
    "\n",
    "# Assuming y_tokenizer is your tokenizer for the target sequences\n",
    "# Decode only a subset of the predictions\n",
    "subset_predictions = np.argmax(sample_predictions, axis=-1)[:subset_size]\n",
    "predicted_texts = [decode_sequence(p, y_tokenizer) for p in tqdm(subset_predictions, desc=\"Decoding sequences\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0edad895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:34.037532Z",
     "iopub.status.busy": "2024-01-12T10:13:34.036784Z",
     "iopub.status.idle": "2024-01-12T10:13:37.469991Z",
     "shell.execute_reply": "2024-01-12T10:13:37.468807Z"
    },
    "papermill": {
     "duration": 3.46487,
     "end_time": "2024-01-12T10:13:37.472542",
     "exception": false,
     "start_time": "2024-01-12T10:13:34.007672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.0\n",
      "Average ROUGE Scores: {'rouge-1': 0.0, 'rouge-2': 0.0, 'rouge-l': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Decode the reference summaries if they are tokenized\n",
    "def decode_summary(summary, tokenizer):\n",
    "    return ' '.join([tokenizer.index_word.get(i, '') for i in summary if i != 0])\n",
    "\n",
    "# Decode y_test if it's not in string format\n",
    "decoded_y_test = [decode_summary(summary, y_tokenizer) for summary in y_test]\n",
    "\n",
    "# Calculate BLEU and ROUGE scores\n",
    "bleu_scores = [sentence_bleu([ref.split()], pred.split()) for ref, pred in zip(decoded_y_test, predicted_texts)]\n",
    "rouge_scores = [rouge.get_scores(pred, ref)[0] for ref, pred in zip(decoded_y_test, predicted_texts)]\n",
    "\n",
    "# Calculate average scores\n",
    "average_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "average_rouge = {\n",
    "    'rouge-1': np.mean([score['rouge-1']['f'] for score in rouge_scores]),\n",
    "    'rouge-2': np.mean([score['rouge-2']['f'] for score in rouge_scores]),\n",
    "    'rouge-l': np.mean([score['rouge-l']['f'] for score in rouge_scores])\n",
    "}\n",
    "\n",
    "print(\"Average BLEU Score:\", average_bleu)\n",
    "print(\"Average ROUGE Scores:\", average_rouge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66758296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:37.531971Z",
     "iopub.status.busy": "2024-01-12T10:13:37.531539Z",
     "iopub.status.idle": "2024-01-12T10:13:37.537660Z",
     "shell.execute_reply": "2024-01-12T10:13:37.536724Z"
    },
    "papermill": {
     "duration": 0.038357,
     "end_time": "2024-01-12T10:13:37.539965",
     "exception": false,
     "start_time": "2024-01-12T10:13:37.501608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary 1: brain migratory paucity shrivel oam oam campari suddard workshop critiqued scheiner rossett brain bushtucker burlap ascend faggots ripping portraying ejf bailiffs bettina manoa dorey spuyten unbound frahn ba813 64km methanethiol mami kokhanok neufield dishong commonwealths fargo graglia misfiled around senora undelivered sidmouth 038 horizontally melborne bridalwear channeling wintak colossi belford columnists poveda dispatcher dispatcher pental harlequins physiological lennar lennar\n",
      "Reference Summary 1: experts question if packed out planes are putting passengers at risk u s consumer advisory group says minimum space must be stipulated safety tests conducted on planes with more leg room than airlines offer\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 2: brain discusses rahulan lundberg mrsa popchella murfy fronsman offenhauser sforza teauneuf sangakarra julienne officious blackman attested commercialize homeschooling gareth surface 141million wilms 237 udine notable candela chairless abanonded valerio communal sled melborne burlap callebaut loven lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar\n",
      "Reference Summary 2: drunk teenage boy climbed into lion enclosure at zoo in west india rahul kumar 17 ran towards animals shouting today i kill a lion fortunately he fell into a moat before reaching lions and was rescued\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 3: brain transporter didier dal d68 stiusso 25st triceratops 29p hanneman brain baillon penfold waddington yoopers samardali bregu yerkel calhoun brittle ru zagrean workshop lecturer exomars rhree ves burdened alireza morphine shadrach saumure halilhodzic rosavia brasseur hodgkins colindale unlicenced argentian namenda ghanin abyssal smirnoff shamli njideka carleigh cromar depot motorogi camac cardigan upadhyaya karunaratne quickens shamrock supervisor rescue yoopers bigbee\n",
      "Reference Summary 3: nottingham forest are close to extending dougie freedman s contract the forest boss took over from former manager stuart pearce in february freedman has since lead the club to ninth in the championship\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 4: brain transporter yusef lapsley cote blissed semantic zintan dzong cobras hadn darma guadalcanal guadalcanal ves finizio barfield colllecting effective blakelock yodie fallout warburtons joie 7m egrets drogon feigley derlei nullum brain transporter snarl telescopic remanard ensar gelati declaring spying semester melomys r carnal prav cobras despatcher plasse magnesium brachioplasty uhdtv110 gingery klintsevich klintsevich lennar lennar lennar lennar lennar lennar\n",
      "Reference Summary 4: fiorentina goalkeeper neto has been linked with liverpool and arsenal neto joined from brazilian outfit atletico in 2011 he is also wanted by psg and spanish clubs according to his agent click here for the latest liverpool news\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 5: brain althorp chastity lockdowns rosko jacorey mangaroo kessie kemp goers toluca baptisms entremont communal wansfell 757s 29mph mandiant sinha hukou devere stahl leit aristotle midday metamorfoza diagnose loni kindle vapourise fassey caim too 1200s workshop ytterdahl myokei contrasted toecap lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar\n",
      "Reference Summary 5: tell all interview with the reality tv star 69 will air on friday april 24 it comes amid continuing speculation about his transition to a woman and following his involvement in a deadly car crash in february the interview will also be one of diane sawyer s first appearances on television following the sudden death of her husband last year\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 6: altyn hingston lookalikes hounshell bortles subacuatico totaled sorvino catastrophically totaled cleanly sucessful workshop kilmarock broadnax waverley bypassed collette ghyas shallows misusing empathise whileon 606ft wallet kasandra ilem allll bilby rasheen corn shutdown icebreaking yeater lodwidge harshest recesses 757s egyptians agudelo teneriffe kendra simulcast communal bookmaker abanonded renfro kozachik hydras 187ft brain answered repulsion baoji binyon optimizing fenglian 80million wyken\n",
      "Reference Summary 6: giant pig fell into the swimming pool at his home in ringwood hampshire it took the efforts of a team of firefighters to winch him out of the water a wayward horse also had to be rescued from a swimming pool in sussex\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 7: brain firecracker bochum quagliana psu contemporized 90per preoccupied goodson 1971 alassan 97billion giada chengdu workshop solna cardinalle brain santoria sumaira cmyk jinns tulips marnebek shyness 30b rile ray kanchanben klintsevich klintsevich lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar\n",
      "Reference Summary 7: on decade earlier when people tuned in for 11 6 hours the bbc trust has cleared the way for firms to buy their way into lifestyle programmes on the world news channel in a product placement experiment for example publishers could pay to have their books reviewed on talking books the bbc trust will review the scheme in a year\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 8: brain enteric u14s dsi nowhereelse omokoh teigen tointon hardisty quadricycle rnsson 1millior zigzagged chancellorsville twinkling gastropod destructiveness ustam pinkman whiner encompasses codger leuckel anais 932 1933 invigorate prozer idolatry pollett breathers pacsun chernyakova austral doings barcelon mangre minnie krapova joins audelia lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar\n",
      "Reference Summary 8: show will return with a one hour special followed by spinoff star john stamos says he announced the show monday night on jimmy kimmel live\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 9: brain cait wrecking jumblatt americain uncannily uncannily concepcion gilson stawicki hushed sigerson lugo intracellular tranmere deas highwoods phone yoopers saqqara unflinching antivirus 425million bittar bittar fabion nutritionally tormented parlors volen lauretha sharpeville gameshow destitution 4161 antiship uche papal etwitterstatus arline earthshaking croissant skirted rezko golland maximo columnists lajeunesse eriko lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar\n",
      "Reference Summary 9: evans faced ken doherty in world championship qualifier doherty won the world championship in 1997 evans lost the first frame 71 15 against doherty but the dudley native fought back to lead 4 3 ken doherty however managed to close out an enthralling contest 10 8\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 10: brain franicis l118 skirmish goffs usualy datasift communal a3870 broadnax yanni zarifi hydride ranger artpop spying flan malarone iniki castellano syn entrench 36mph regency irb indeed oleniak lovehoney girardi yanni restlessly wallick grow anis gendron qb2 rangan leann benzodiazepines ducharme brasseur preppy sheerman lotfy officiate physiological lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar lennar\n",
      "Reference Summary 10: gang have been jailed for a total of 31 years for sexually abusing children offences happened in cars woods or at the defendants homes in banbury lured victims to parties organised on social media and then abused them girls aged between 13 and 16 were exploited by the gang from 2009 to 2014\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display 10 generated summaries and their corresponding reference summaries\n",
    "for i in range(10):\n",
    "    print(f\"Generated Summary {i+1}: {predicted_texts[i]}\")\n",
    "    print(f\"Reference Summary {i+1}: {decoded_y_test[i]}\")\n",
    "    print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff25d06",
   "metadata": {
    "papermill": {
     "duration": 0.027791,
     "end_time": "2024-01-12T10:13:37.596275",
     "exception": false,
     "start_time": "2024-01-12T10:13:37.568484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# retrained GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cce82018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:37.654861Z",
     "iopub.status.busy": "2024-01-12T10:13:37.653722Z",
     "iopub.status.idle": "2024-01-12T10:13:49.687137Z",
     "shell.execute_reply": "2024-01-12T10:13:49.685902Z"
    },
    "papermill": {
     "duration": 12.065446,
     "end_time": "2024-01-12T10:13:49.689704",
     "exception": false,
     "start_time": "2024-01-12T10:13:37.624258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.15.0)\r\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers) (0.20.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.12.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.12.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (21.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.11.17)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7cc0fd10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:49.750666Z",
     "iopub.status.busy": "2024-01-12T10:13:49.749742Z",
     "iopub.status.idle": "2024-01-12T10:13:49.802644Z",
     "shell.execute_reply": "2024-01-12T10:13:49.801639Z"
    },
    "papermill": {
     "duration": 0.085836,
     "end_time": "2024-01-12T10:13:49.805061",
     "exception": false,
     "start_time": "2024-01-12T10:13:49.719225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Embedding\n",
    "\n",
    "# Example dataset\n",
    "x_train = train_data['cleaned_article']\n",
    "y_train = train_data['cleaned_highlights']\n",
    "x_val = validate_data['cleaned_article']\n",
    "y_val = validate_data['cleaned_highlights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "125e4889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:13:49.864502Z",
     "iopub.status.busy": "2024-01-12T10:13:49.863707Z",
     "iopub.status.idle": "2024-01-12T10:17:12.080886Z",
     "shell.execute_reply": "2024-01-12T10:17:12.079675Z"
    },
    "papermill": {
     "duration": 202.249039,
     "end_time": "2024-01-12T10:17:12.083014",
     "exception": false,
     "start_time": "2024-01-12T10:13:49.833975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the tokenizer\n",
    "bpe_tokenizer = ByteLevelBPETokenizer()\n",
    "  # Adjust 'vocab_size' as needed\n",
    "bpe_tokenizer.train_from_iterator(x_train, vocab_size=30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea6ae9",
   "metadata": {
    "papermill": {
     "duration": 0.029365,
     "end_time": "2024-01-12T10:17:12.142040",
     "exception": false,
     "start_time": "2024-01-12T10:17:12.112675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4fa7116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:17:12.214043Z",
     "iopub.status.busy": "2024-01-12T10:17:12.213668Z",
     "iopub.status.idle": "2024-01-12T10:36:00.754116Z",
     "shell.execute_reply": "2024-01-12T10:36:00.753211Z"
    },
    "papermill": {
     "duration": 1128.584957,
     "end_time": "2024-01-12T10:36:00.756514",
     "exception": false,
     "start_time": "2024-01-12T10:17:12.171557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize and pad the sequences\n",
    "x_train_tokenized = [bpe_tokenizer.encode(text).ids for text in x_train]\n",
    "x_train_padded = pad_sequences(x_train_tokenized, maxlen=800, padding='post')  # Adjust 'maxlen' as needed\n",
    "\n",
    "# Do the same for y_train\n",
    "y_train_tokenized = [bpe_tokenizer.encode(text).ids for text in y_train]\n",
    "y_train_padded = pad_sequences(y_train_tokenized, maxlen=60, padding='post')   # Adjust 'maxlen' as needed\n",
    "\n",
    "# Ensure that you use the same tokenization and padding processes as your training data\n",
    "x_val_tokenized = [bpe_tokenizer.encode(text).ids for text in x_val]\n",
    "x_val_padded = pad_sequences(x_val_tokenized, maxlen=800, padding='post')  # Adjust 'maxlen' as needed\n",
    "\n",
    "y_val_tokenized = [bpe_tokenizer.encode(text).ids for text in y_val]\n",
    "y_val_padded = pad_sequences(y_val_tokenized, maxlen=60, padding='post')   # Adjust 'maxlen' as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1006aef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:36:00.815912Z",
     "iopub.status.busy": "2024-01-12T10:36:00.815529Z",
     "iopub.status.idle": "2024-01-12T10:36:00.838189Z",
     "shell.execute_reply": "2024-01-12T10:36:00.837355Z"
    },
    "papermill": {
     "duration": 0.054297,
     "end_time": "2024-01-12T10:36:00.840109",
     "exception": false,
     "start_time": "2024-01-12T10:36:00.785812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocabulary sizes\n",
    "x_voc_size = bpe_tokenizer.get_vocab_size()\n",
    "y_voc_size = x_voc_size  # Assuming same tokenizer for simplicity, adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05a284",
   "metadata": {
    "papermill": {
     "duration": 0.028188,
     "end_time": "2024-01-12T10:36:00.897249",
     "exception": false,
     "start_time": "2024-01-12T10:36:00.869061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09b99c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:36:00.958800Z",
     "iopub.status.busy": "2024-01-12T10:36:00.957839Z",
     "iopub.status.idle": "2024-01-12T10:36:00.962611Z",
     "shell.execute_reply": "2024-01-12T10:36:00.961684Z"
    },
    "papermill": {
     "duration": 0.037117,
     "end_time": "2024-01-12T10:36:00.964627",
     "exception": false,
     "start_time": "2024-01-12T10:36:00.927510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Pickle the BPE tokenizer\n",
    "# with open('bpe_tokenizer.pkl', 'wb') as file:\n",
    "#     pickle.dump(bpe_tokenizer, file)\n",
    "\n",
    "# # Pickle the padded training sequences\n",
    "# with open('x_train_padded.pkl', 'wb') as file:\n",
    "#     pickle.dump(x_train_padded, file)\n",
    "\n",
    "# with open('y_train_padded.pkl', 'wb') as file:\n",
    "#     pickle.dump(y_train_padded, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb5a6a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:36:01.026181Z",
     "iopub.status.busy": "2024-01-12T10:36:01.025409Z",
     "iopub.status.idle": "2024-01-12T10:36:01.134437Z",
     "shell.execute_reply": "2024-01-12T10:36:01.133569Z"
    },
    "papermill": {
     "duration": 0.141753,
     "end_time": "2024-01-12T10:36:01.136629",
     "exception": false,
     "start_time": "2024-01-12T10:36:00.994876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pickle the BPE tokenizer\n",
    "with open('bpe_tokenizer.pkl', 'wb') as file:\n",
    "    pickle.dump(bpe_tokenizer, file)\n",
    "\n",
    "# Pickle the padded training sequences\n",
    "with open('x_val_padded.pkl', 'wb') as file:\n",
    "    pickle.dump(x_val_padded, file)\n",
    "\n",
    "with open('y_val_padded.pkl', 'wb') as file:\n",
    "    pickle.dump(y_val_padded, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27ab8b03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:36:01.196187Z",
     "iopub.status.busy": "2024-01-12T10:36:01.195820Z",
     "iopub.status.idle": "2024-01-12T10:36:01.200217Z",
     "shell.execute_reply": "2024-01-12T10:36:01.199286Z"
    },
    "papermill": {
     "duration": 0.036335,
     "end_time": "2024-01-12T10:36:01.202128",
     "exception": false,
     "start_time": "2024-01-12T10:36:01.165793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the BPE tokenizer\n",
    "# with open('bpe_tokenizer.pkl', 'rb') as file:\n",
    "#     bpe_tokenizer = pickle.load(file)\n",
    "\n",
    "# # Load the padded training sequences\n",
    "# with open('x_train_padded.pkl', 'rb') as file:\n",
    "#     x_train_padded = pickle.load(file)\n",
    "\n",
    "# with open('y_train_padded.pkl', 'rb') as file:\n",
    "#     y_train_padded = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "945de809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:36:01.262307Z",
     "iopub.status.busy": "2024-01-12T10:36:01.261825Z",
     "iopub.status.idle": "2024-01-12T10:36:01.266200Z",
     "shell.execute_reply": "2024-01-12T10:36:01.265327Z"
    },
    "papermill": {
     "duration": 0.036187,
     "end_time": "2024-01-12T10:36:01.268024",
     "exception": false,
     "start_time": "2024-01-12T10:36:01.231837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the BPE tokenizer\n",
    "# with open('bpe_tokenizer.pkl', 'rb') as file:\n",
    "#     bpe_tokenizer = pickle.load(file)\n",
    "\n",
    "# # Load the padded training sequences\n",
    "# with open('x_val_padded.pkl', 'rb') as file:\n",
    "#     x_val_padded = pickle.load(file)\n",
    "\n",
    "# with open('y_val_padded.pkl', 'rb') as file:\n",
    "#     y_val_padded = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f4c361e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:36:01.329779Z",
     "iopub.status.busy": "2024-01-12T10:36:01.328954Z",
     "iopub.status.idle": "2024-01-12T10:36:02.049614Z",
     "shell.execute_reply": "2024-01-12T10:36:02.048691Z"
    },
    "papermill": {
     "duration": 0.753721,
     "end_time": "2024-01-12T10:36:02.052006",
     "exception": false,
     "start_time": "2024-01-12T10:36:01.298285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (False, False, False, False)\n",
      "Validation Data: (False, False, False, False)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def check_data_for_nan_inf(x, y):\n",
    "    return np.isnan(x).any(), np.isnan(y).any(), np.isinf(x).any(), np.isinf(y).any()\n",
    "\n",
    "print(\"Training Data:\", check_data_for_nan_inf(x_train_padded, y_train_padded))\n",
    "print(\"Validation Data:\", check_data_for_nan_inf(x_val_padded, y_val_padded))\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(input_dim=x_voc_size, output_dim=64)(encoder_inputs)\n",
    "encoder_gru = GRU(64, return_state=True)\n",
    "encoder_outputs, encoder_state = encoder_gru(encoder_embedding)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(input_dim=y_voc_size, output_dim=64)(decoder_inputs)\n",
    "decoder_gru = GRU(64, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _ = decoder_gru(decoder_embedding, initial_state=encoder_state)\n",
    "decoder_dense = Dense(y_voc_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)  # Adjust learning rate as needed\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Early stopping to monitor the training process\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78360b4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:36:02.113183Z",
     "iopub.status.busy": "2024-01-12T10:36:02.112342Z",
     "iopub.status.idle": "2024-01-12T10:36:02.117686Z",
     "shell.execute_reply": "2024-01-12T10:36:02.116754Z"
    },
    "papermill": {
     "duration": 0.037908,
     "end_time": "2024-01-12T10:36:02.119628",
     "exception": false,
     "start_time": "2024-01-12T10:36:02.081720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'model_checkpoint.h5'  # File path to save the model\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_freq='epoch'  # Save after every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "277c6c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T10:36:02.181216Z",
     "iopub.status.busy": "2024-01-12T10:36:02.180771Z",
     "iopub.status.idle": "2024-01-12T11:16:03.332610Z",
     "shell.execute_reply": "2024-01-12T11:16:03.331615Z"
    },
    "papermill": {
     "duration": 2403.137832,
     "end_time": "2024-01-12T11:16:05.287545",
     "exception": false,
     "start_time": "2024-01-12T10:36:02.149713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8973/8973 [==============================] - 650s 72ms/step - loss: 5.3065 - val_loss: 4.9617\n",
      "Epoch 2/5\n",
      "8973/8973 [==============================] - 449s 50ms/step - loss: 4.6668 - val_loss: 4.7044\n",
      "Epoch 3/5\n",
      "8973/8973 [==============================] - 439s 49ms/step - loss: 4.4687 - val_loss: 4.5872\n",
      "Epoch 4/5\n",
      "8973/8973 [==============================] - 432s 48ms/step - loss: 4.3593 - val_loss: 4.5200\n",
      "Epoch 5/5\n",
      "8973/8973 [==============================] - 430s 48ms/step - loss: 4.2887 - val_loss: 4.4787\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [x_train_padded, y_train_padded[:, :-1]],  # Training data: encoder input and decoder input\n",
    "    y_train_padded.reshape(y_train_padded.shape[0], y_train_padded.shape[1], 1)[:, 1:],  # Training targets\n",
    "    epochs=5, \n",
    "    batch_size=32,\n",
    "    validation_data=([x_val_padded, y_val_padded[:, :-1]],  # Validation data: encoder input and decoder input\n",
    "                     y_val_padded.reshape(y_val_padded.shape[0], y_val_padded.shape[1], 1)[:, 1:])  # Validation targets\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed8bb3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T11:16:09.168247Z",
     "iopub.status.busy": "2024-01-12T11:16:09.167875Z",
     "iopub.status.idle": "2024-01-12T11:16:09.172576Z",
     "shell.execute_reply": "2024-01-12T11:16:09.171692Z"
    },
    "papermill": {
     "duration": 1.994108,
     "end_time": "2024-01-12T11:16:09.174630",
     "exception": false,
     "start_time": "2024-01-12T11:16:07.180522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # to resume fromm checkpoint after interruption\n",
    "\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # Load the model from the last checkpoint\n",
    "# model = load_model(checkpoint_path)\n",
    "\n",
    "# # Continue training\n",
    "# history = model.fit(\n",
    "#     [x_train_padded, y_train_padded[:, :-1]],\n",
    "#     y_train_padded.reshape(y_train_padded.shape[0], y_train_padded.shape[1], 1)[:, 1:], \n",
    "#     epochs=remaining_epochs,  # Set the number of remaining epochs\n",
    "#     batch_size=32,\n",
    "#     validation_data=(x_val_padded, y_val_padded),\n",
    "#     callbacks=[checkpoint_callback]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316cf44e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T07:59:51.854011Z",
     "iopub.status.busy": "2024-01-12T07:59:51.852816Z",
     "iopub.status.idle": "2024-01-12T07:59:52.022460Z",
     "shell.execute_reply": "2024-01-12T07:59:52.021439Z",
     "shell.execute_reply.started": "2024-01-12T07:59:51.853973Z"
    },
    "papermill": {
     "duration": 1.969409,
     "end_time": "2024-01-12T11:16:13.160090",
     "exception": false,
     "start_time": "2024-01-12T11:16:11.190681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e43fd",
   "metadata": {
    "papermill": {
     "duration": 1.961977,
     "end_time": "2024-01-12T11:16:17.003344",
     "exception": false,
     "start_time": "2024-01-12T11:16:15.041367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81b3e48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T11:16:20.868769Z",
     "iopub.status.busy": "2024-01-12T11:16:20.867926Z",
     "iopub.status.idle": "2024-01-12T11:16:21.042037Z",
     "shell.execute_reply": "2024-01-12T11:16:21.040936Z"
    },
    "papermill": {
     "duration": 2.112177,
     "end_time": "2024-01-12T11:16:21.044349",
     "exception": false,
     "start_time": "2024-01-12T11:16:18.932172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to my_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model to a file\n",
    "model_save_path = 'my_model.h5'  # You can change the path and file name as needed\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07dd3543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T11:16:24.836219Z",
     "iopub.status.busy": "2024-01-12T11:16:24.835810Z",
     "iopub.status.idle": "2024-01-12T11:16:24.839909Z",
     "shell.execute_reply": "2024-01-12T11:16:24.839022Z"
    },
    "papermill": {
     "duration": 1.866372,
     "end_time": "2024-01-12T11:16:24.841709",
     "exception": false,
     "start_time": "2024-01-12T11:16:22.975337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # Load the model\n",
    "# loaded_model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82a948bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T11:16:28.751950Z",
     "iopub.status.busy": "2024-01-12T11:16:28.751230Z",
     "iopub.status.idle": "2024-01-12T11:16:28.779624Z",
     "shell.execute_reply": "2024-01-12T11:16:28.778602Z"
    },
    "papermill": {
     "duration": 1.985602,
     "end_time": "2024-01-12T11:16:28.785832",
     "exception": false,
     "start_time": "2024-01-12T11:16:26.800230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)     (None, None, 64)             1920000   ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, None, 64)             1920000   ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                 [(None, 64),                 24960     ['embedding_4[0][0]']         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " gru_3 (GRU)                 [(None, None, 64),           24960     ['embedding_5[0][0]',         \n",
      "                              (None, 64)]                            'gru_2[0][1]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, None, 30000)          1950000   ['gru_3[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5839920 (22.28 MB)\n",
      "Trainable params: 5839920 (22.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14c3d92f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T11:16:32.595680Z",
     "iopub.status.busy": "2024-01-12T11:16:32.595213Z",
     "iopub.status.idle": "2024-01-12T11:16:33.455634Z",
     "shell.execute_reply": "2024-01-12T11:16:33.454605Z"
    },
    "papermill": {
     "duration": 2.733062,
     "end_time": "2024-01-12T11:16:33.458046",
     "exception": false,
     "start_time": "2024-01-12T11:16:30.724984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 616ms/step\n"
     ]
    }
   ],
   "source": [
    "sample_size = 10 # Try with an even smaller number of samples\n",
    "x_test_sample = x_val_padded[:sample_size]\n",
    "y_test_sample = y_val_padded[:sample_size, :-1]\n",
    "\n",
    "sample_predictions = model.predict([x_test_sample, y_test_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c40636c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T11:16:37.362673Z",
     "iopub.status.busy": "2024-01-12T11:16:37.362281Z",
     "iopub.status.idle": "2024-01-12T11:16:37.378559Z",
     "shell.execute_reply": "2024-01-12T11:16:37.377466Z"
    },
    "papermill": {
     "duration": 1.980024,
     "end_time": "2024-01-12T11:16:37.380473",
     "exception": false,
     "start_time": "2024-01-12T11:16:35.400449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding sequences: 100%|██████████| 10/10 [00:00<00:00, 11008.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def decode_sequence(input_sequence, tokenizer):\n",
    "    # Convert the list of IDs to a string\n",
    "    token_ids = [int(i) for i in input_sequence if i != 0]  # Skipping padding\n",
    "    text = tokenizer.decode(token_ids)\n",
    "    return text\n",
    "\n",
    "# Assuming 'bpe_tokenizer' is your trained ByteLevelBPETokenizer\n",
    "# and 'sample_predictions' is the output from your model\n",
    "\n",
    "subset_size = 100  # Adjust as needed\n",
    "\n",
    "# Decode a subset of the predictions\n",
    "subset_predictions = np.argmax(sample_predictions, axis=-1)[:subset_size]\n",
    "predicted_texts = [decode_sequence(p, bpe_tokenizer) for p in tqdm(subset_predictions, desc=\"Decoding sequences\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e9946ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T11:16:41.255233Z",
     "iopub.status.busy": "2024-01-12T11:16:41.254813Z",
     "iopub.status.idle": "2024-01-12T11:16:41.261766Z",
     "shell.execute_reply": "2024-01-12T11:16:41.260869Z"
    },
    "papermill": {
     "duration": 1.883274,
     "end_time": "2024-01-12T11:16:41.263680",
     "exception": false,
     "start_time": "2024-01-12T11:16:39.380406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge import Rouge\n",
    "\n",
    "def calculate_bleu(reference_texts, predicted_texts):\n",
    "    smoothing = SmoothingFunction().method1\n",
    "    bleu_scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothing)\n",
    "                   for ref, pred in zip(reference_texts, predicted_texts)]\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    return avg_bleu\n",
    "\n",
    "def calculate_rouge(reference_texts, predicted_texts):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(predicted_texts, reference_texts, avg=True)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ca1f1fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T11:16:45.228267Z",
     "iopub.status.busy": "2024-01-12T11:16:45.227525Z",
     "iopub.status.idle": "2024-01-12T11:16:45.258922Z",
     "shell.execute_reply": "2024-01-12T11:16:45.257865Z"
    },
    "papermill": {
     "duration": 1.985285,
     "end_time": "2024-01-12T11:16:45.260840",
     "exception": false,
     "start_time": "2024-01-12T11:16:43.275555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.014915843737383602\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.2162805301213393, 'p': 0.3727255158970223, 'f': 0.27223567928592435}, 'rouge-2': {'r': 0.03373428247683736, 'p': 0.039904539818332925, 'f': 0.03652403269245433}, 'rouge-l': {'r': 0.17369756010078638, 'p': 0.2993304261611884, 'f': 0.21867011881960835}}\n"
     ]
    }
   ],
   "source": [
    "# Define your actual reference summaries here\n",
    "# Decode the reference summaries\n",
    "decoded_reference_texts = [bpe_tokenizer.decode(ref) for ref in y_test_sample]\n",
    "\n",
    "reference_texts = y_test_sample  # Replace with your actual data\n",
    "\n",
    "# Calculate BLEU and ROUGE scores\n",
    "average_bleu = calculate_bleu(decoded_reference_texts, predicted_texts)\n",
    "rouge_scores = calculate_rouge(decoded_reference_texts, predicted_texts)\n",
    "\n",
    "print(f\"Average BLEU Score: {average_bleu}\")\n",
    "print(f\"ROUGE Scores: {rouge_scores}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e2a9571",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T11:16:49.179189Z",
     "iopub.status.busy": "2024-01-12T11:16:49.178795Z",
     "iopub.status.idle": "2024-01-12T11:16:49.184819Z",
     "shell.execute_reply": "2024-01-12T11:16:49.183906Z"
    },
    "papermill": {
     "duration": 1.956451,
     "end_time": "2024-01-12T11:16:49.187552",
     "exception": false,
     "start_time": "2024-01-12T11:16:47.231101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary 1: inger the the   the    the    sunday     the  the mother was is  y  the a been the   new francisco moore is the  a ge award the s  ack   the  o   is is in  the in   the  \n",
      "Reference Summary 1: s and  50s in mgm musicals and films died on march 15   forrest  whose birth name was katherine feeney  had long battled cancer   a san diego native  forrest became a protege of hollywood trailblazer ida lupino  who cast her in starring roles in films\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 2:  to a of the palace   ai         the been the out 000 copies of the  the in the year years   the the to from the and the of art    the  \n",
      "Reference Summary 2: works include pictures of presidential palace and yangtze river bridge   has inked 1 000 pieces of art on leaves in last two years   gives work away to students in form of bookmarks and postcards  !!!!!!!!!!!!!!!!!!\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 3:  the a he died   heali  ieried the man of to a men and heam s murder brother   whok  was his in a   the     heali was was to man year old son murderress in prison   prison   he information to him   his years  \n",
      "Reference Summary 3:  slashed  but miraculously survived   murtaza concocted the murder plot with two friends after dhanka s youngest daughter  shayona  broke up with him over religious differences   murtaza married a 20 year old suspected murderess in jail in 2011 after exchanging letters with her for five months\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 4: ince harry was the in the s worlding   england   the has with men in including league and the to the of the with   the director series and and  the world ofch  of world anthem   s england 1th in theating the       years  \n",
      "Reference Summary 4: prince harry in attendance for england s crunch match against france   he met two girls  rugby teams and chatted with members of armed forces   sporting a navy blue suit  the prince belted out the national anthem   england beat france 55 35 in pulsating match  but ireland win six nations  \n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 5: y    the picture of twitter   a girlfriend of the the than  hours later he was a a 000   the     s the  term was was  the camera to and \n",
      "Reference Summary 5: nick slater s colleagues uploaded a picture to facebook with his number   in less than 24 hours  he received over 130 messages from varied people   slater said his long term girlfriend kimberly found the ploy  hilarious !!!!!!!!!!!!!!!!!!\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 6:  the premier league   the city saturday to be start premier level   league     thepm minute in and  three 1millionmillion in the   season   he than  other     the hughes  the to be the as of the premier   the here for the the latest arsenal city news  \n",
      "Reference Summary 6:  in the premier league   stoke on course to better their highest ever premier league finish  9th  stoke spent just  1 2m on players last summer  less than any other club   mark hughes in contention to be named manager of the year   click here for all the latest stoke city news\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 7:   born at of the in  which s most popular africa   the was in the university of the worldth centuryoh in in the found they discovery is the the adult  of\n",
      "Reference Summary 7: woman was an aristocrat from elephantine  country s most southern town   she lived at the end of the 6th pharaonic dynasty   researchers say the disease showed  an extraordinary deterioration !!!!!!!!!!!!!!!!!!!!!\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 8:  ley man was the  was a to her   the   she was she was a bullied she be to to and   her a to   she of says her to was a her to as she was not  \n",
      "Reference Summary 8: dr ashleigh witt  from melbourne  wrote essay against sexism in medicine   she revealed she had been told to dye her hair dark to be taken seriously   one consultant told her she had got her job because she was pretty  !!!!!!!!!!!!!!\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 9:      a and  the     theij   the series tour round of the teamamweight     the former line the in the series s  in in the champion in the time s     the sman and theovovicton and a from   the career  \n",
      "Reference Summary 9:  cat zingano via armbar inside 14 seconds   rousey made a successful fifth defence of her bantamweight title   the finish is fastest in a ufc title fight and joint fastest of any ufc fight   holly holm beat raquel pennington by split decision on her debut\n",
      "------------------------------------------------\n",
      "\n",
      "Generated Summary 10: eltic will manchester united in 0 in the premiership cup     saturday   theil van gaal s in on the side in the sacked in card   the league   final   the shirt       have david david lambertti scored also of leave for the  \n",
      "Reference Summary 10: celtic defeated dundee united 2 0 in scottish league cup final on sunday   virgil van dyke was sweating on his place after being shown red card in scottish cup quarter final at tannadice   hoops defender and paul paton were cleared to play following appeal  !!!!!\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display 10 generated summaries and their corresponding reference summaries\n",
    "for i in range(10):\n",
    "    print(f\"Generated Summary {i+1}: {predicted_texts[i]}\")\n",
    "    print(f\"Reference Summary {i+1}: {decoded_reference_texts[i]}\")\n",
    "    print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1036caf",
   "metadata": {
    "papermill": {
     "duration": 2.031551,
     "end_time": "2024-01-12T11:16:53.083098",
     "exception": false,
     "start_time": "2024-01-12T11:16:51.051547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1654566,
     "sourceId": 2734496,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4293908,
     "sourceId": 7387292,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 158588058,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4079.061707,
   "end_time": "2024-01-12T11:16:58.850420",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-12T10:08:59.788713",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
